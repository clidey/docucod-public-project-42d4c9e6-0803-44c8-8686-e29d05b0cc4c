---
title: "System Integration Points"
description: "Learn how SBNN integrates C++/CUDA routines with data preprocessing steps, supports loading binary weights from the PyTorch ecosystem, and how user customization (e.g., dataset paths, GPU selection) works. A glance at the current and planned expansion toward training scripts and external model compatibility."
---

# System Integration Points

Discover how SBNN seamlessly integrates its high-performance C++ and CUDA routines with essential data preprocessing steps, enabling efficient loading of binarized weights from the PyTorch ecosystem. This page guides you through configuring dataset paths, selecting GPUs for inference, and customizing integration points—providing a clear pathway for extending functionality toward training and broader external model support.

---

## Why Integration Matters

SBNN thrives as a GPU-focused framework optimized for binarized neural network (BNN) inference, but its real-world value emerges from how it fits into your existing ML workflows. Understanding the integration points where SBNN's low-level CUDA kernels meet data input, weight loading, and user configurations empowers you to deploy BNNs efficiently and customize workflows to your needs.

Whether you are running established models like ResNet-18 or VGG on ImageNet/CIFAR-10 or experimenting with your own datasets, this page clarifies how SBNN expects data and model parameters to flow and how you can adapt those to your environment.

---

## Integrating C++/CUDA Routines with Data Preprocessing

At the core, SBNN is implemented with performance-critical CUDA kernels coded in C++ (e.g., `imagenet_resnet.cu`, `cifar10_resnet.cu`). These kernels are designed to run entire binarized networks as cooperative GPU kernels for maximum throughput.

### Data Preprocessing Interface

- **Image Data Loading:** SBNN includes C++ functions (`read_ImageNet_normalized`, `read_CIFAR10_normalized`, `read_MNIST_normalized`) that handle dataset loading from raw image files or binary dumps. These functions normalize and preprocess images (e.g., RGB normalization, resizing) to match the expected floating-point tensor input.
- **Input Preparation:** Raw input images are loaded into host memory and then copied into GPU buffers before BNN inference.

### Feeding Inputs into CUDA Kernels

- Input layers such as `In32Conv32LayerParam` or `In32LayerParam` encapsulate preprocessed image tensors, manage GPU memory allocation, and prepare bit-packed input data representations for the BNN kernels.
- Each network layer object initializes its weights and batch normalization parameters from CSV configuration files generated by PyTorch training scripts, converting float weights into compact binary forms on the GPU.

### Kernel Launch Workflow

- An example can be seen in the `main64()` function of `imagenet_resnet.cu`, where:
  - The device GPU is selected via `cudaSetDevice()`.
  - The batch size, input image dimensions, and output size are declared.
  - Weights and thresholds are loaded from PyTorch-produced CSV files.
  - Layer parameter objects are created and initialized (input, convolutional layers, fully connected, output layers).
  - CUDA cooperative kernels are launched using `cudaLaunchCooperativeKernel()` for seamless execution of the entire BNN model.

---

## Loading Binary Weights from PyTorch Ecosystem

SBNN builds on pretrained binarized neural network weights exported from PyTorch training scripts, stored as CSV files with weights and batch normalization parameters.

### Weight Loading and Binarization

- CSV files (e.g., `resnet_imagenet.csv`, `vgg_cifar10.csv`) provide floating-point weights.
- Upon initialization, each layer's `initialize` method reads these CSV files, loads float weights into host memory, and launches bit-packing CUDA kernels (`PackFcWeight32/64`, `PackFiltersByOutChannels32/64`) that convert float weights to optimized binary representations on the GPU.
- Batch normalization parameters are similarly loaded and transferred to GPU buffers.

### Benefits

- This automated binarization bridges the gap between training in PyTorch's floating-point domain and efficient GPU inference with bit-wise kernels.
- Enables users to reuse existing PyTorch-trained BNN models directly within SBNN without rewriting or manually converting weights.

---

## User Configuration and Customization

SBNN offers straightforward customization options for adapting to different datasets, GPUs, and deployment scenarios:

### Dataset Paths

- Dataset locations for ImageNet, CIFAR-10, and MNIST are typically specified as strings (file paths or directories) in the C++ source files or via configuration.
- For example, the ImageNet loading function targets `"./imagenet_files.txt"`, which lists image file paths.
- CIFAR-10 and MNIST directories are likewise configurable as needed.


### GPU Selection

- Users specify the target GPU device ID by calling `cudaSetDevice(device_id)` early in the main program.
- This enables deployment flexibility in multi-GPU systems.

### Batch Size and Image Dimensions

- Key parameters such as batch size, image height and width, and output classes are constants within example main functions but can be modified to match your workload.

### Model Selection and SBNN Variant

- Switching between the SBNN32 and SBNN64 implementations involves choosing the corresponding `main32()` or `main64()` entry points.
- Source files for each network (e.g., ResNet, AlexNet, VGG) include implementations for both 32-bit and 64-bit modes.

---

## Towards Training Script Integration and External Model Support

- Currently, SBNN focuses on inference by consuming pretrained weights and optimized CUDA kernels.
- Future expansions plan to incorporate training scripts, allowing direct BNN model training within the SBNN ecosystem.
- Broader model compatibility beyond supported pretrained architectures (ResNet-18, AlexNet, VGG, MLP) is anticipated, with an aim toward seamless integration of externally developed BNN models.

---

## Best Practices for Successful Integration

- **Maintain Dataset Consistency:** Align your input datasets with SBNN preprocessing expectations, especially normalization and size.
- **Use Provided Training Exports:** Utilize or adapt PyTorch training scripts to generate weight CSV files compatible with SBNN.
- **Match GPU Architecture:** Compile with appropriate architecture flags (e.g., `sm_70`) in `Makefile` matching your GPU.
- **Adjust Batch Size Carefully:** Batch size impacts GPU utilization and performance; tune per your hardware.
- **Validate Outputs:** Use `validate_prediction()` routines to ensure outputs align with expected results.

---

## Troubleshooting Common Integration Issues

<AccordionGroup title="Common Issues in System Integration">
<Accordion title="CUDA Device Not Found or Cannot Set Device">
Ensure the GPU device ID specified in `cudaSetDevice()` matches an available device.
Verify CUDA drivers and runtime are properly installed.
</Accordion>
<Accordion title="Dataset Path or File Not Found">
Check that dataset files or directory paths (e.g., `imagenet_files.txt`) are correctly set and accessible to the executable.
File permissions can cause silent failures.
</Accordion>
<Accordion title="CSV Weight File Not Read Properly">
Confirm the CSV weight files are present and correspond to the expected network architecture.
Use provided PyTorch export scripts to generate fresh CSV files if needed.
</Accordion>
<Accordion title="Memory Allocation Failures on GPU">
Verify your GPU has sufficient memory for the chosen batch size and model.
Consider reducing batch size or image resolution if out-of-memory errors occur.
</Accordion>
</AccordionGroup>

---

## Example: Integration Workflow Overview

1. **Prepare input images** on disk along with label files.
2. **Set dataset paths and GPU device ID** in your C++ example source code.
3. **Compile your target executable** with appropriate `Makefile` commands.
4. **Run the executable**, which:
   - Reads and normalizes input images into GPU buffers.
   - Loads PyTorch-exported binary weights and BN parameters into GPU memory.
   - Initializes layer objects representing network layers.
   - Invokes the fused CUDA cooperative kernel to run the entire network inference.
   - Downloads output predictions and validates accuracy.

---

For detailed code examples, see the source files in the repository for:
- [ImageNet ResNet-18 Integration](../imagenet_resnet.cu)
- [CIFAR-10 ResNet Integration](../cifar10_resnet.cu)
- [AlexNet for ImageNet](../alexnet.cu)
- [MNIST MLP Example](../mnist_mlp.cu)

These examples illustrate step-by-step how preprocessing, weight loading, GPU kernel launches, and outputs are orchestrated.

---

For extended learning, consult:
- [Dataset Preparation & Verification](../getting-started/run-validate/dataset-preparation)
- [Target Audience & Use Cases](../overview/use-cases-integration/audience-use-cases)
- [What is SBNN?](../overview/introduction-core-concepts/what-is-sbnn)
- [Supported Models & Datasets](../overview/product-architecture-features/supported-models-datasets)

---

Harnessing the full power of SBNN starts with understanding these critical system integration points—setting the foundation for efficient, flexible, and scalable binarized neural network inference on GPUs.


---

<Info>
For implementation details and source code references, see the associated `.cu` files in the GitHub repository: [SBNN GitHub Repo](https://github.com/uuudown/SBNN).
</Info>
